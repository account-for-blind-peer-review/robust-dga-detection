{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a443c57a-bde7-440b-9553-2d7c8ca8220c",
   "metadata": {},
   "source": [
    "# Combining Embedding Space Attack with Controllable Discretization\n",
    "This notebook contains example code for generating fully valid adversarial e2LDs by combining\n",
    "an embedding-space adversarial attack with a discretization scheme.\n",
    "\n",
    "The concepts are explained step by step, allowing you to apply these attacks to your own models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab7c172-843e-4c4e-b09f-fced92166270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from robust_dga_detection.models import CNNResNetWithEmbedding\n",
    "from robust_dga_detection.utils import domains, reproduceability\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reproduceability.setup_deterministic_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9097dcf8-7cad-4951-90ce-6dc33ba11aa8",
   "metadata": {},
   "source": [
    "## Step 1: Load a model to attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92197c62-579e-4552-9850-2751aed635f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNResNetWithEmbedding().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d962b8-8159-4f40-8ad4-0f2652e6ec46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(os.getenv(\"TRAINED_MODEL_PATH\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5bddd6-d6bb-4bc5-ab53-28d458504d8e",
   "metadata": {},
   "source": [
    "## Step 2: Setup an embedding-space attack\n",
    "\n",
    "As most adversarial attack libraries require inputs that have similar shapes to images, we introduce a transparent translation layer to meet these expectations.\n",
    "\n",
    "**NOTE**: This adaptation layer performs some caching during creation. Therefore, it must be re-created when the model is updated in any way to avoid inconsistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e3d5bd-e4df-434e-a7f5-54ba797110d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robust_dga_detection.attacks.embedding_space import ImageEmulationAdapter\n",
    "from foolbox import PyTorchModel\n",
    "\n",
    "image_model = ImageEmulationAdapter(model).eval()\n",
    "foolbox_model = PyTorchModel(image_model, bounds=(0, 1), device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f2819-9728-460a-a1f9-caf70bc927ed",
   "metadata": {},
   "source": [
    "In this framework, an embedding-space attack is a function that maps a scaled batch of embedded domain names with labels to\n",
    "a scaled batch of adversarial examples.\n",
    "\n",
    "$$\n",
    "    \\mathrm{atk}: [0, 1]^{n \\times w \\times d} \\times \\{0, 1\\}^n \\rightarrow [0, 1]^{n \\times w \\times d}\n",
    "$$\n",
    "Below, we provide example attack functions for all attacks we used in our paper. **Please selectively execute only the cell for the attack you want to use.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb29315-4a2e-488f-9a3b-4d755c59fba4",
   "metadata": {},
   "source": [
    "### Binary AutoAttack $L_2$\n",
    "Modified version of AutoAttack using an $L_2$ norm bound introduced in the paper\n",
    "\n",
    "Francesco Croce and Matthias Hein. “Reliable evaluation of adversarial ro-\n",
    "bustness with an ensemble of diverse parameter-free attacks”. In: Proceedings\n",
    "of the 37th International Conference on Machine Learning. Ed. by Hal Daumé III\n",
    "and Aarti Singh. Vol. 119. Proceedings of Machine Learning Research. PMLR,\n",
    "2020, pp. 2206–2216. url: https://proceedings.mlr.press/v119/croce20b.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67db1eff-c691-4a9f-8082-b26d684bc21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robust_dga_detection.attacks.embedding_space import BinaryAutoAttack\n",
    "eps_l2 = 50\n",
    "attack_function = BinaryAutoAttack(model=image_model, eps=eps_l2, norm=\"L2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec84eb-1fd5-4c0f-8c1d-51eb7d8ed529",
   "metadata": {},
   "source": [
    "### Binary AutoAttack $L_\\infty$\n",
    "Modified version of AutoAttack using an $L_\\infty$ norm bound introduced in the paper\n",
    "\n",
    "Francesco Croce and Matthias Hein. “Reliable evaluation of adversarial ro-\n",
    "bustness with an ensemble of diverse parameter-free attacks”. In: Proceedings\n",
    "of the 37th International Conference on Machine Learning. Ed. by Hal Daumé III\n",
    "and Aarti Singh. Vol. 119. Proceedings of Machine Learning Research. PMLR,\n",
    "2020, pp. 2206–2216. url: https://proceedings.mlr.press/v119/croce20b.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f1c6b-4de0-41db-a7c3-3e0a52b4878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robust_dga_detection.attacks.embedding_space import BinaryAutoAttack\n",
    "eps_linf = 0.5\n",
    "attack_function = BinaryAutoAttack(model=image_model, eps=eps_linf, norm=\"Linf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cdd866-d841-42ff-b29b-b90eda6582d7",
   "metadata": {},
   "source": [
    "### Projected Gradient Descent $L_2$ attack\n",
    "The PGD attack using an $L_2$ norm bound introduced in the paper\n",
    "\n",
    "Aleksander Madry et al. “Towards Deep Learning Models Resistant to Ad-\n",
    "versarial Attacks”. In: 6th International Conference on Learning Representations,\n",
    "ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Pro-\n",
    "ceedings. OpenReview.net, 2018. url: https://openreview.net/forum?id=rJzIBfZAb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9486281a-f84d-49c8-9978-b8483ae27b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchattacks\n",
    "eps_l2 = 50\n",
    "attack_function = torchattacks.PGDL2(model=image_model, eps=eps_l2, steps=50, random_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0aa556-8ae6-4082-ac8e-8731005cfe82",
   "metadata": {},
   "source": [
    "### Projected Gradient Descent $L_\\infty$ attack\n",
    "\n",
    "The PGD attack using an $L_\\infty$ norm bound introduced in the paper\n",
    "\n",
    "Aleksander Madry et al. “Towards Deep Learning Models Resistant to Ad-\n",
    "versarial Attacks”. In: 6th International Conference on Learning Representations,\n",
    "ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Pro-\n",
    "ceedings. OpenReview.net, 2018. url: https://openreview.net/forum?id=rJzIBfZAb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662b5c2-9d21-4190-9932-1047d9f9fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchattacks\n",
    "eps_linf = 0.5\n",
    "attack_function = torchattacks.PGD(model=image_model, eps=eps_linf, steps=50, random_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4f92d-9355-4433-96c9-ccd6e7d47e3d",
   "metadata": {},
   "source": [
    "### Carlini & Wagner $L_2$ Attack\n",
    "\n",
    "The C&W attack using an $L_2$ norm bound introduced in the paper\n",
    "\n",
    "Nicholas Carlini and David Wagner. “Towards Evaluating the Robustness\n",
    "of Neural Networks”. In: 2017 IEEE Symposium on Security and Privacy (SP).\n",
    "May 2017, pp. 39–57. doi: 10.1109/SP.2017.49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17dacc4-c06e-4578-b4ae-7e189d204e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox\n",
    "\n",
    "cw_confidence = 0\n",
    "cw = foolbox.attacks.L2CarliniWagnerAttack(steps=50, confidence=cw_confidence)\n",
    "\n",
    "def cw_attack_fun(inputs, labels):\n",
    "    criterion = foolbox.Misclassification(labels)\n",
    "    _, adv_examples, _ = cw(\n",
    "        foolbox_model,\n",
    "        inputs,\n",
    "        criterion,\n",
    "        epsilons=128,\n",
    "    )\n",
    "    return adv_examples\n",
    "\n",
    "attack_function = cw_attack_fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccf9117-453f-42ee-8766-3b2dbcbc244c",
   "metadata": {},
   "source": [
    "## Step 3: Setup a discretization scheme\n",
    "A discretization scheme translates the generated adversarial embedding vectors back to adversarial domain names. In our paper, we develop six different discretization schemes with individual strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eccbaa21-b756-4b34-a0bd-5d1b165f9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robust_dga_detection.attacks.discretization import E2lDDiscretizerWithLengthBruteForce, E2lDDiscretizerWithLengthCutoff, RoundingNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532f2626-74f1-47e2-8674-13318a6949b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "discretization_schemes = {\n",
    "    \"len_bf_l2_min_7\": E2lDDiscretizerWithLengthBruteForce(\n",
    "        model, norm=RoundingNorm.L_2, minimum_output_length=7\n",
    "    ),\n",
    "    \"len_bf_linf_min_7\": E2lDDiscretizerWithLengthBruteForce(\n",
    "        model, norm=RoundingNorm.L_INF, minimum_output_length=7\n",
    "    ),\n",
    "    \"len_bf_cos_min_7\": E2lDDiscretizerWithLengthBruteForce(\n",
    "        model, norm=RoundingNorm.COS, minimum_output_length=7\n",
    "    ),\n",
    "    \"len_cutoff_l2_min_7\": E2lDDiscretizerWithLengthCutoff(\n",
    "        model, norm=RoundingNorm.L_2, minimum_output_length=7\n",
    "    ),\n",
    "    \"len_cutoff_linf_min_7\": E2lDDiscretizerWithLengthCutoff(\n",
    "        model, norm=RoundingNorm.L_INF, minimum_output_length=7\n",
    "    ),\n",
    "    \"len_cutoff_cos_min_7\": E2lDDiscretizerWithLengthCutoff(\n",
    "        model, norm=RoundingNorm.COS, minimum_output_length=7\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e493b-e3b1-4b48-9756-2d29c05237a6",
   "metadata": {},
   "source": [
    "## Step 4: Putting it all together to generate adversarial domain names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e53ff5fe-89cb-4dac-b3db-42cd366ee610",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_domain = \"lmlabssssssssentasdasdasdasdasdasdasd\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e8c68-4192-4cf8-87e5-620150aacdab",
   "metadata": {},
   "source": [
    "Measure the models prediction on the input domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1976c286-7e63-4694-8f8d-bece6db3738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model value: 0.9897634983062744\n"
     ]
    }
   ],
   "source": [
    "encoded_domains = torch.unsqueeze(domains.encode_domain(input_domain), dim=0).to(DEVICE)\n",
    "labels = torch.Tensor([1]).long().to(DEVICE)\n",
    "print(f\"Baseline model value: {torch.sigmoid(model(encoded_domains)).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f5464-4c2e-4d76-a66a-49a1a4968437",
   "metadata": {},
   "source": [
    "Apply the embedding space attack to obtain an embedding vector that results in a strong negative prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41e5151a-3a3e-49c4-8c6a-3d56e2e46d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model value on adversarial embedding vector: 0.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embedded_domains = model.embedding(encoded_domains)\n",
    "\n",
    "adversarial_embedding_vectors = image_model.apply_attack(attack_function, embedded_domains, labels) \n",
    "print(f\"Model value on adversarial embedding vector: {torch.sigmoid(model.net(adversarial_embedding_vectors)).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b6723-b06a-43d3-b4b7-49d0aa462e7a",
   "metadata": {},
   "source": [
    "Use the discretization schemes to recover domain names that (hopefully) retain the strong negative prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e71efec-7a67-41b4-9199-301293ca8dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_bf_l2_min_7 generated the domain:\n",
      "\t'080gvxjsiulisugqqqvxqrmlmlae-ssai--------89s----------app0-0'\n",
      "\twith model value 0.0\n",
      "\n",
      "len_bf_linf_min_7 generated the domain:\n",
      "\t'ckdkvvngpuourojujjavmrmlecassssuaeea8ykgkw9mvaak8vkdsea0vea2'\n",
      "\twith model value 4.922889318415002e-10\n",
      "\n",
      "len_bf_cos_min_7 generated the domain:\n",
      "\t'1--gvxjmxulisugqqjvvkrmlmla--ssai--------89s----------a-p0-0'\n",
      "\twith model value 0.0\n",
      "\n",
      "len_cutoff_l2_min_7 generated the domain:\n",
      "\t'iapp0-0'\n",
      "\twith model value 4.6235862782850745e-07\n",
      "\n",
      "len_cutoff_linf_min_7 generated the domain:\n",
      "\t'ea0vea2'\n",
      "\twith model value 0.12092402577400208\n",
      "\n",
      "len_cutoff_cos_min_7 generated the domain:\n",
      "\t'0a-p0-0'\n",
      "\twith model value 2.1017700913006365e-09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for disc_name, discretization_scheme in discretization_schemes.items():\n",
    "    discrete_adversarial_examples = discretization_scheme(encoded_domains, adversarial_embedding_vectors)\n",
    "    print(f\"{disc_name} generated the domain:\\n\\t'{domains.decode_domains(discrete_adversarial_examples)[0]}'\\n\\twith model value {torch.sigmoid(model(discrete_adversarial_examples)).item()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e637ef-ffbb-49d1-aba9-6213544827c5",
   "metadata": {},
   "source": [
    "We hope this notebook provided you with the details required for testing your models against our attacks.\n",
    "Nevertheless, do not hesitate to reach out if you have any questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
