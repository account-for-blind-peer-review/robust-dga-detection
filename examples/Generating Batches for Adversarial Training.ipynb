{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b1a7f3-cf2e-4b1b-947a-806ab5c8642b",
   "metadata": {},
   "source": [
    "# Generating Batches for Adversarial Training\n",
    "This notebook contains example code for generating batches that could be used for adversarially training a classifier against our attacks.\n",
    "\n",
    "**Note**: We deliberately describe the individual steps required for performing adversarial training rather than providing a pre-defined adversarial training loop as part of this library. This is because, from our experience, the latter is usually not flexible enough to cater to varying training schemes and architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87320acf-e565-4063-9ad1-4760721fb771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from robust_dga_detection.models import CNNResNetWithEmbedding\n",
    "from robust_dga_detection.utils import domains, reproduceability\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reproduceability.setup_deterministic_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b77e7-4c77-45b2-8ad0-48cc82ef0a08",
   "metadata": {},
   "source": [
    "## Step 1: Load a model to generate adversarial training batches for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f69083-8109-4a5c-9716-c06d7495a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNResNetWithEmbedding().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaea5b9b-b6f4-4930-b6ea-dff83b685498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(os.getenv(\"TRAINED_MODEL_PATH\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12ea31a-f7cf-4675-b538-3ff75e143ff2",
   "metadata": {},
   "source": [
    "## Step 2: Setup data for the adversarial batch\n",
    "\n",
    "Our batch generation functions aim to apply a wide range of adversarial attacks to the same batch of examples by splitting them into sufficient pieces. Therefore, you need at least 42 input samples to generate one domain per attack configuration. Nevertheless, we recommend choosing larger batch sizes. Internally, we randomly sample attack hyperparameters for every batch.\n",
    "\n",
    "In the following, we generate example domains as $\\mathrm{MD5}(i)$, which could just as well be generated by a real DGA. In a real use case, you would replace this with the portion of the mini-batch you want to create adversarial examples for (e.g., $50 \\%$ of samples as in our paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f326c5b-de11-4d5b-9f4b-3ffff8c95406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def get_hash_domain(i):\n",
    "    m = hashlib.md5()\n",
    "    m.update(str(i).encode('ascii'))\n",
    "    return m.hexdigest()\n",
    "\n",
    "input_domains_to_generate_adversarial_examples_for = [\n",
    "    get_hash_domain(i) for i in range(42)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e321f-2788-46f5-ac81-0eb15a72387e",
   "metadata": {},
   "source": [
    "Next, we encode the domains for the classifier and check the baseline prediction before applying adversarial attacks to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd838de-613b-453c-9afe-9e02e9b3b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_domains = torch.stack(\n",
    "    [domains.encode_domain(domain) for domain in input_domains_to_generate_adversarial_examples_for]\n",
    ").to(DEVICE)\n",
    "labels = torch.ones(len(input_domains_to_generate_adversarial_examples_for)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0f36f9-cec7-4a34-8a62-cb3370014826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9999, 0.9949, 1.0000, 0.9912, 1.0000, 0.9997, 1.0000, 1.0000, 0.9997,\n",
      "        1.0000, 1.0000, 0.9980, 0.9992, 1.0000, 0.9987, 1.0000, 0.9999, 0.9997,\n",
      "        1.0000, 0.9938, 1.0000, 1.0000, 0.9965, 0.9997, 0.9997, 0.9999, 0.9997,\n",
      "        1.0000, 1.0000, 0.9956, 1.0000, 0.9999, 0.9999, 1.0000, 0.9999, 0.9999,\n",
      "        0.9999, 0.9918, 0.9991, 1.0000, 0.9999, 0.9999], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(torch.sigmoid(model(encoded_domains)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a3d46-c92a-467d-ac99-0084fdf7ac22",
   "metadata": {},
   "source": [
    "## Step 3: Apply Alternating Adversarial Training\n",
    "In our paper, we recommend alternating between generating adversarial latent space vectors and generating adversarial domains for adversarial training.\n",
    "\n",
    "In the following, we show how you can use this library to generate both kinds of batches to give you the most flexibility in using this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0389aa1-dbf4-4dc2-af00-81afe0aa58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robust_dga_detection import defenses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0caae5-a1ab-4f96-92ef-a5d05c233064",
   "metadata": {},
   "source": [
    "You can configure our batch attack functions only to use a subset of the implemented attacks (e.g., for LOGO evaluations).\n",
    "Therefore, you must specify which attacks you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e14d37c-2926-4372-97e5-b6787af9c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_space_attacks_to_use = {x for x in defenses.EmbeddingSpaceAttackCatalogue}\n",
    "discretization_schemes_to_use = {x for x in defenses.EmbeddingSpaceDiscretizationCatalogue}\n",
    "nlp_attacks_to_use = {x for x in defenses.NLPAttackCatalogue}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e709c472-a9f1-4953-a17b-c87c0c805d13",
   "metadata": {},
   "source": [
    "### Option 1 - Generate adversarial embedding space vectors\n",
    "In this setting, we generate adversarial embedding vectors. Therefore, we must first embed the domains for which we want to create adversarial samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6134073-f78f-40d1-b440-7c4d06a47ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embedded_domains = model.embedding(encoded_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4564e-c89c-431a-b22c-9360757c95fd",
   "metadata": {},
   "source": [
    "Afterward, we can apply the attack function to the entire batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17499269-74df-4ce5-abe8-79f20a1d1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_space_batch_attack = defenses.EmbeddingSpaceBatchAttack(model, embedding_space_attacks_to_use)\n",
    "embedding_space_adversarial_batch = embedding_space_batch_attack.attack(embedded_domains, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60331b47-178f-4c29-9794-e1ea9c22e548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4840e-11, 1.6182e-11, 1.3771e-11,\n",
       "        1.8895e-11, 1.7746e-11, 1.9103e-11, 1.8332e-11, 1.9157e-11, 1.5997e-11,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(model.net(embedding_space_adversarial_batch).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525e558-2c07-4e3f-adc1-6f3e3cbc9caa",
   "metadata": {},
   "source": [
    "We can observe that the attack succeeded! The generated adversarial embedding space vectors can now be re-combined with the benign samples and used as an adversarial training batch!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4fe94d-2bbd-4c45-a2d7-28d1f78a36eb",
   "metadata": {},
   "source": [
    "### Option 2 - Generate adversarial domain names\n",
    "In this setting, we generate adversarial domain names by combining embedding space attacks with discretization or by directly using discrete attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da738ad-ac35-4564-8e50-1d6bbb127f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_batch_attack = defenses.DiscreteDomainbatchAttack(\n",
    "    model,\n",
    "    embedding_space_attacks_to_use,\n",
    "    discretization_schemes_to_use,\n",
    "    nlp_attacks_to_use\n",
    ")\n",
    "discrete_adversarial_batch = discrete_batch_attack.attack(encoded_domains, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13001708-b9f0-4184-9654-97e62189e6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.4454e-10, 9.9487e-01, 0.0000e+00, 0.0000e+00, 2.9638e-04, 2.9467e-06,\n",
       "        9.9999e-01, 9.9999e-01, 8.8217e-03, 1.5801e-01, 2.1580e-01, 9.9805e-01,\n",
       "        3.8359e-08, 1.0000e+00, 0.0000e+00, 0.0000e+00, 3.8751e-04, 9.9606e-08,\n",
       "        1.0594e-09, 1.9512e-01, 6.9340e-03, 1.5028e-12, 7.5694e-06, 3.5234e-10,\n",
       "        1.2796e-07, 1.1281e-01, 0.0000e+00, 0.0000e+00, 4.0686e-26, 2.0022e-09,\n",
       "        5.1103e-27, 3.2958e-34, 1.8424e-27, 3.6021e-29, 3.2991e-27, 1.7414e-28,\n",
       "        4.1944e-25, 1.7541e-27, 4.8127e-24, 1.4819e-24, 7.5002e-22, 2.4673e-23],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(model(discrete_adversarial_batch).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f3e23d-ec77-4ae9-b48f-5037902b3c53",
   "metadata": {},
   "source": [
    "Again, we observe that the adversarial domain generation succeeded (in most cases, as seen below). The generated adversarial domains can now be re-combined with the benign samples and used as a batch for adversarial training.\n",
    "\n",
    "In our paper, we randomly alternate between Option 1 and Option 2. We do not apply both options to the same batch. We do so here only for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddae2734-cbb5-4f92-ba79-5263d3fc0594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "         True, False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edade4b-7c01-4f28-b103-9dd23f95d4b5",
   "metadata": {},
   "source": [
    "During the adversarial training evaluations in our paper, we generate adversarial domains freshly for every training minibatch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5babf959-fe41-4e92-982a-82f0b6cec5fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We hope this notebook helped you start hardening your classifier against our attacks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
